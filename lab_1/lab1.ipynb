{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1 - Scikit-learn\n",
    "Author: *YOUR NAME*\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "The goal of this lab is to become familiar with the scikit-learn library.\n",
    "\n",
    "You will practice loading example datasets, perform classification and regression with linear scikit-learn models, and investigate the effects of reducing the number of features (columns in X) and the number of samples (rows in X and y).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification\n",
    "\n",
    "Using yellowbrick spam - classification  \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "The goal is to investigate `LogisticRegression(max_iter=2000)` and effects of reducing the number of features and number of samples on classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Implement convenience function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_classifier_accuracy(model, X, y):\n",
    "    '''Calculate train and validation accuracy of classifier (model)\n",
    "        \n",
    "        Splits feature matrix X and target vector y \n",
    "        with sklearn train_test_split() and random_state=956.\n",
    "        \n",
    "        model (sklearn classifier): Classifier to train and evaluate\n",
    "        X (numpy.array or pandas.DataFrame): Feature matrix\n",
    "        y (numpy.array or pandas.Series): Target vector\n",
    "        \n",
    "        returns: training accuracy, validation accuracy\n",
    "    \n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "    #TODO: IMPLEMENT FUNCTION BODY\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=956)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)   \n",
    "    y_pred_test = model.predict(X_test)\n",
    "    train_acc = accuracy_score(y_train, y_pred_train)\n",
    "    test_acc = accuracy_score(y_test, y_pred_test)\n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load data\n",
    "\n",
    "Use the yellowbrick function `load_spam()`, load the spam data set into feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print size and type of `X` and `y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4600, 57)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(4600,)\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.21               0.28           0.50           0.0   \n",
       "1            0.06               0.00           0.71           0.0   \n",
       "2            0.00               0.00           0.00           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.14            0.28              0.21                0.07   \n",
       "1           1.23            0.19              0.19                0.12   \n",
       "2           0.63            0.00              0.31                0.63   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           1.85            0.00              0.00                1.85   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n",
       "0             0.00            0.94  ...                   0.0         0.00   \n",
       "1             0.64            0.25  ...                   0.0         0.01   \n",
       "2             0.31            0.63  ...                   0.0         0.00   \n",
       "3             0.31            0.63  ...                   0.0         0.00   \n",
       "4             0.00            0.00  ...                   0.0         0.00   \n",
       "\n",
       "   char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0        0.132          0.0        0.372        0.180        0.048   \n",
       "1        0.143          0.0        0.276        0.184        0.010   \n",
       "2        0.137          0.0        0.137        0.000        0.000   \n",
       "3        0.135          0.0        0.135        0.000        0.000   \n",
       "4        0.223          0.0        0.000        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       5.114                         101   \n",
       "1                       9.821                         485   \n",
       "2                       3.537                          40   \n",
       "3                       3.537                          40   \n",
       "4                       3.000                          15   \n",
       "\n",
       "   capital_run_length_total  \n",
       "0                      1028  \n",
       "1                      2259  \n",
       "2                       191  \n",
       "3                       191  \n",
       "4                        54  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: ADD YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "from yellowbrick import datasets\n",
    "\n",
    "X, y = datasets.load_spam() \n",
    "print(X.shape)\n",
    "print(type(X))\n",
    "print(y.shape)\n",
    "print(type(y))\n",
    "\n",
    "X.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the sklearn function `train_test_split()` prepare a feature matrix `X_small` and target vector `y_small` that contain only **1%** of the rows. Use `random_state=174`.\n",
    "\n",
    "Print size and type of `X_small` and `y_small`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 57)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(46,)\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TODO: ADD YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "X_small, _, y_small, _ = train_test_split(X, y, train_size=0.01, random_state=174)\n",
    "print(X_small.shape)\n",
    "print(type(X_small))\n",
    "print(y_small.shape)\n",
    "print(type(y_small))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Train and evaluate models\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "4. Call your convenience function `get_classifier_accuracy()` using \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`\n",
    "5. Add the data size, training and validation accuracy for each call to the `results` DataFrame\n",
    "6. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ADD YOUR CODE HERE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "\n",
    "results = pd.DataFrame(columns=[\"data size\", \"training acc\", \"validation acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jb/h7p_6zx90lq3mlgz6102t6ww0000gn/T/ipykernel_93608/798509156.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"data size\": X.shape, \"training acc\": get_classifier_accuracy(model, X,y)[0], \"validation acc\": get_classifier_accuracy(model, X,y)[1]}, ignore_index=True)\n",
      "/var/folders/jb/h7p_6zx90lq3mlgz6102t6ww0000gn/T/ipykernel_93608/798509156.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results  = results.append({\"data size\": X.iloc[:,:2].shape, \"training acc\": get_classifier_accuracy(model, X.iloc[:,:2],y)[0], \"validation acc\": get_classifier_accuracy(model, X.iloc[:,:2],y)[1]}, ignore_index=True)\n",
      "/var/folders/jb/h7p_6zx90lq3mlgz6102t6ww0000gn/T/ipykernel_93608/798509156.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"data size\": X_small.shape, \"training acc\": get_classifier_accuracy(model, X_small,y_small)[0], \"validation acc\": get_classifier_accuracy(model, X_small,y_small)[1]}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#print(get_classifier_accuracy(model, X,y))\n",
    "# get_classifier_accuracy(only first two columns of X,y)\n",
    "\n",
    "\n",
    "results = results.append({\"data size\": X.shape, \"training acc\": get_classifier_accuracy(model, X,y)[0], \"validation acc\": get_classifier_accuracy(model, X,y)[1]}, ignore_index=True)\n",
    "\n",
    "results  = results.append({\"data size\": X.iloc[:,:2].shape, \"training acc\": get_classifier_accuracy(model, X.iloc[:,:2],y)[0], \"validation acc\": get_classifier_accuracy(model, X.iloc[:,:2],y)[1]}, ignore_index=True)\n",
    "\n",
    "results = results.append({\"data size\": X_small.shape, \"training acc\": get_classifier_accuracy(model, X_small,y_small)[0], \"validation acc\": get_classifier_accuracy(model, X_small,y_small)[1]}, ignore_index=True)\n",
    "\n",
    "\n",
    "# print(get_classifier_accuracy(model, X.iloc[:,:2],y))\n",
    "\n",
    "# print(get_classifier_accuracy(model, X_small,y_small))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data size</th>\n",
       "      <th>training acc</th>\n",
       "      <th>validation acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(4600, 57)</td>\n",
       "      <td>0.935072</td>\n",
       "      <td>0.917391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(4600, 2)</td>\n",
       "      <td>0.608986</td>\n",
       "      <td>0.613043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(46, 57)</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    data size training acc validation acc\n",
       "0  (4600, 57)     0.935072       0.917391\n",
       "1   (4600, 2)     0.608986       0.613043\n",
       "2    (46, 57)     0.941176           0.75"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Questions\n",
    "1. What is the validation accuracy using all data? What is the difference between training and validation accuracy?\n",
    "1. How does the validation accuracy and difference between training and validation change when only two columns are used? Provide values.\n",
    "1. How does the validation accuracy and difference between training and validation change when only 1% of the rows are used? Provide values.\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using all the data: 91.73% accuracy. Training accuracy measures how accurately our model fits the data it was trained on. Validation accuracy measures how accurately our model fits new unseen data, which it was not trained on.\n",
    "\n",
    "2. Comparing all columns with only two columns, the validation accuracy decreases from 91.73% to 61.30 %. The Training accuracy decreases from 93.5% to 60.8%. \n",
    "\n",
    "3. Comparing using all rows vs only 1% of rows, the Training accuracy increased from 93.5% to 94.11% , the validation accuracy decreased from 91.73% to 75% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regression\n",
    "\n",
    "Using yellowbrick energy - regression  \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/energy.html\n",
    "\n",
    "The goal is to investigate `LinearRegression()` and effects of reducing the number of features and number of samples on regression performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Implement convenience function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_regressor_mse(model, X, y):\n",
    "    '''Calculate train and validation mean-squared error (mse) of regressor (model)\n",
    "        \n",
    "        Splits feature matrix X and target vector y \n",
    "        with sklearn train_test_split() and random_state=956.\n",
    "        \n",
    "        model (sklearn regressor): Regressor to train and evaluate\n",
    "        X (numpy.array or pandas.DataFrame): Feature matrix\n",
    "        y (numpy.array or pandas.Series): Target vector\n",
    "        \n",
    "        returns: training mse, validation mse\n",
    "    \n",
    "    '''\n",
    "   \n",
    "    #TODO: IMPLEMENT FUNCTION BODY\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=956)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "    test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "    return train_mse, test_mse\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load data\n",
    "\n",
    "Use the yellowbrick function `load_energy()` load the energy data set into feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print dimensions and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(768,)\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TODO: ADD YOUR CODE HERE\n",
    "Xe,ye=datasets.load_energy()\n",
    "\n",
    "print(Xe.shape)\n",
    "print(type(Xe))\n",
    "print(ye.shape)\n",
    "print(type(ye))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the sklearn function `train_test_split()` prepare a feature matrix `X_small` and target vector `y_small` that contain only **1%** of the rows. Use `random_state=174`.\n",
    "\n",
    "Print size and type of `X_small` and `y_small`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(7,)\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TODO: ADD YOUR CODE HERE\n",
    "Xe_small, _, ye_small, _ = train_test_split(Xe, ye, train_size=0.01, random_state=174)\n",
    "\n",
    "print(Xe_small.shape)\n",
    "print(type(Xe_small))\n",
    "print(ye_small.shape)\n",
    "print(type(ye_small))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Train and evaluate models\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`.\n",
    "3. Create a pandas DataFrame `results` with columns: Data size, training MSE, validation MSE\n",
    "4. Call your convenience function `get_regressor_mse()` using \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`\n",
    "5. Add the data size, training and validation MSE for each call to the `results` DataFrame\n",
    "6. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jb/h7p_6zx90lq3mlgz6102t6ww0000gn/T/ipykernel_93608/3555247351.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_LR = results_LR.append({\"data size\": Xe.shape, \"training mse\": get_regressor_mse(model_LR, Xe,ye)[0], \"validation mse\": get_regressor_mse(model_LR, Xe,ye)[1]}, ignore_index=True)\n",
      "/var/folders/jb/h7p_6zx90lq3mlgz6102t6ww0000gn/T/ipykernel_93608/3555247351.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_LR = results_LR.append({\"data size\": Xe.iloc[:,:2].shape, \"training mse\": get_regressor_mse(model_LR, Xe.iloc[:,:2],ye)[0], \"validation mse\": get_regressor_mse(model_LR, Xe.iloc[:,:2],ye)[1]}, ignore_index=True)\n",
      "/var/folders/jb/h7p_6zx90lq3mlgz6102t6ww0000gn/T/ipykernel_93608/3555247351.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_LR = results_LR.append({\"data size\": Xe_small.shape, \"training mse\": get_regressor_mse(model_LR, Xe_small,ye_small)[0], \"validation mse\": get_regressor_mse(model_LR, Xe_small,ye_small)[1]}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# TODO: ADD YOUR CODE HERE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_LR = LinearRegression()\n",
    "\n",
    "results_LR = pd.DataFrame(columns=[\"data size\", \"training mse\", \"validation mse\"])\n",
    "\n",
    "results_LR = results_LR.append({\"data size\": Xe.shape, \"training mse\": get_regressor_mse(model_LR, Xe,ye)[0], \"validation mse\": get_regressor_mse(model_LR, Xe,ye)[1]}, ignore_index=True)\n",
    "\n",
    "results_LR = results_LR.append({\"data size\": Xe.iloc[:,:2].shape, \"training mse\": get_regressor_mse(model_LR, Xe.iloc[:,:2],ye)[0], \"validation mse\": get_regressor_mse(model_LR, Xe.iloc[:,:2],ye)[1]}, ignore_index=True)\n",
    "\n",
    "results_LR = results_LR.append({\"data size\": Xe_small.shape, \"training mse\": get_regressor_mse(model_LR, Xe_small,ye_small)[0], \"validation mse\": get_regressor_mse(model_LR, Xe_small,ye_small)[1]}, ignore_index=True)\n",
    "# print(get_regressor_mse(model_LR, Xe,ye))\n",
    "# print(get_regressor_mse(model_LR, Xe.iloc[:,:2],ye))\n",
    "# print(get_regressor_mse(model_LR, Xe_small,ye_small))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data size</th>\n",
       "      <th>training mse</th>\n",
       "      <th>validation mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(768, 8)</td>\n",
       "      <td>7.969557</td>\n",
       "      <td>10.323016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(768, 2)</td>\n",
       "      <td>53.60043</td>\n",
       "      <td>46.410426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(7, 8)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.977449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data size training mse validation mse\n",
       "0  (768, 8)     7.969557      10.323016\n",
       "1  (768, 2)     53.60043      46.410426\n",
       "2    (7, 8)          0.0      69.977449"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Questions\n",
    "1. What is the validation MSE using all data? What is the difference between training and validation MSE?\n",
    "1. How does the validation MSE and difference between training and validation change when only two columns are used? Provide values.\n",
    "1. How does the validation MSE and difference between training and validation change when only 1% of the rows are used? Provide values.\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using all the data, Training MSE is 7.97. Training MSE measures how accurately our model fits the data it was trained on. Validation MSE using all the data is 10.32 Validation MSE measures how accurately our model fits new unseen data, which it was not trained on.\n",
    "\n",
    "2. Training MSE increases from 7.97 to 53.6 Validation MSE increases from 10.32 to 46.41\n",
    "\n",
    "3. Training MSE decreases from 7.97 to 0.0 Validation MSE increases from 10.32 to 69.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Observations/Interpretation\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training accuracy and MSE both decrease when only using 1% of rows, however the validation accuracy and MSE both increase. This is because using only 1% is overfitting the data. New data is not being predicted well because the model is too specific to the small amount of training data. \n",
    "\n",
    "When using only first two columns of training data ,  the training/validation accuracy decreases and MSE increases, which is expected because the model is not as accurate as when using all the data to be trained on. \n",
    "\n",
    "\n",
    "When using all the data, we get relatively acceptable results. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reflection\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I liked implementing the convenience functions to streamline generating results. Seeing how different results were produced by adjusting the data was interesting. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "805dd3c4e07083ec131e1f936d9092f34c52878c3b4f561482d74a43e1836f21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
